__config_filebeat: |
  #通过emptyDir将需要采集的日志挂载出来，然后在宿主机就能通过指定路径读取改日志
  filebeat.autodiscover:
    providers:

    - type: kubernetes
      templates:


      - config:
        {% for li in log.elastic.filebeat.log -%}
        - type: log
          paths: {{ li.paths }}
          fields:
            labels:
              app_name: "{{ li.app_name }}"
              addition: "host"
              source: "host"
              timezone: "{{ li.timezone }}"
              host: "${data.kubernetes.node.name}"
          fields_under_root: true

        {% endfor -%}

      #收集k8s中所有容器的日志（需要排除上面特殊处理的日志）
      - condition:
          and:
          - not:
              regexp:
                kubernetes.pod.name: "filebeat|logstash"
          - not:
              regexp:
                kubernetes.pod.name: "iot-.*-backend"
          - not:
              equals:
                kubernetes.container.name: "istio-proxy"
        config:
        - type: container
          paths:
          - "/var/log/containers/*${data.kubernetes.container.id}.log"

  #给容器日志添加相应标签
  processors:
  - add_labels:
      labels:
        app_env: {{ log.elastic.filebeat.env }}
  - add_labels:
      labels:
        timezone: UTC
      when:
        not:
          has_fields: ['labels.timezone']
  - add_labels:
      labels:
        source: container
      when:
        not:
          has_fields: ['labels.source']

  - copy_fields:
      fields:
      - from: kubernetes.container.name
        to: labels.app_name
      - from: kubernetes.namespace
        to: labels.addition
      - from: kubernetes.pod.name
        to: labels.pod
      - from: kubernetes.node.name
        to: labels.host
      fail_on_error: false
      ignore_missing: true
      when:
        and:
        - has_fields: ['kubernetes']
        - not:
            equals:
              labels.source: "host"

  #输出到kafka
  output.kafka:
    hosts: {{ __kafka }}
    topic: 'all-logs_topic'
    partition.round_robin:
      reachable_only: true    #当有partition不可达，数据会发送到可到达的partition
